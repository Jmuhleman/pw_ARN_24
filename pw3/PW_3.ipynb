{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce3c6e79-e91a-4977-9c1b-5d072890d965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras import layers\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "import random as random\n",
    "\n",
    "\n",
    "trainset_1 = pd.read_csv('EEG_mouse_data_1.csv')\n",
    "trainset_2 = pd.read_csv('EEG_mouse_data_2.csv')\n",
    "testset_1 = pd.read_csv('EEG_mouse_data_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89259083-a986-41b3-8731-5d0bc5ffec46",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return true;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6da8a2f1-dbed-4659-b9a4-ae462f1333ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualisation des données par classe\n",
    "def show_boxplots(df):\n",
    "    fig, axs = plt.subplots(20, 5, figsize=(25, 120))\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    for i, col in enumerate(df.columns[1:]):\n",
    "        sns.boxplot(x='state', y=col, data=df, ax=axs[i])\n",
    "    \n",
    "    fig.suptitle('Boxplot of the amplitudes', fontsize=14)\n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 0.98])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80eb5be8-ffee-4049-8106-af0b36722ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normlisation des features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "def normalize(df):\n",
    "    headers = df.columns\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    numerical_columns = df.select_dtypes(include=['int', 'float']).columns\n",
    "    df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
    "    normalized_data = pd.DataFrame(df, columns=headers[:-1])\n",
    "\n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af779e76-9a23-4c4f-bef6-99f6c6717d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraction des colonnes\n",
    "# envisager de faire la séléction des features ici\n",
    "def extract_features(data, n):\n",
    "    return data.iloc[:,:n+1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "2f90bd09-db1c-4942-baa3-2a1485c4d38c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_11\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_11\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                      </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">        Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━┩\n",
       "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">78</span> │\n",
       "├───────────────────────────────────┼───────────────────────────┼────────────────┤\n",
       "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span> │\n",
       "└───────────────────────────────────┴───────────────────────────┴────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━┩\n",
       "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                 │             \u001b[38;5;34m78\u001b[0m │\n",
       "├───────────────────────────────────┼───────────────────────────┼────────────────┤\n",
       "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m4\u001b[0m │\n",
       "└───────────────────────────────────┴───────────────────────────┴────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">82</span> (328.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m82\u001b[0m (328.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">82</span> (328.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m82\u001b[0m (328.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_model():\n",
    "  # 2 inputs\n",
    "  # 2 hidden nodes\n",
    "  # 1 output\n",
    "\n",
    "  mlp = keras.Sequential([\n",
    "      layers.Input(shape=(25,)),\n",
    "      layers.Dense(3, activation=\"tanh\"), # Try different numbers of hidden neurons here (e.g. 2, 4, 8, 32, 128)\n",
    "      layers.Dense(1, activation=\"tanh\"),\n",
    "  ])\n",
    "\n",
    "  # Experiment with hyperparameters here:\n",
    "  # momentum: [0, 0.8, 0.9, 0.99]\n",
    "  # learning_rate: [0.1, 0.01, 0.001, 0.0001]\n",
    "  mlp.compile(\n",
    "      optimizer=keras.optimizers.SGD(learning_rate=0.01, momentum=0.99),\n",
    "      loss=\"mse\",\n",
    "  )\n",
    "\n",
    "  return mlp\n",
    "mlp = create_model()\n",
    "mlp.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "57da11fb-5087-4e02-ad77-51eb36b0374b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2346 - val_loss: 0.0988\n",
      "Epoch 2/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0966 - val_loss: 0.0807\n",
      "Epoch 3/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0833 - val_loss: 0.0770\n",
      "Epoch 4/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0811 - val_loss: 0.0752\n",
      "Epoch 5/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0790 - val_loss: 0.0735\n",
      "Epoch 6/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0781 - val_loss: 0.0731\n",
      "Epoch 7/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0780 - val_loss: 0.0729\n",
      "Epoch 8/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0778 - val_loss: 0.0726\n",
      "Epoch 9/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0782 - val_loss: 0.0722\n",
      "Epoch 10/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0781 - val_loss: 0.0760\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[154], line 25\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fold, (train_index, test_index) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(kf\u001b[38;5;241m.\u001b[39msplit(normal_trainset_1)):\n\u001b[0;32m     23\u001b[0m     model \u001b[38;5;241m=\u001b[39m create_model()\n\u001b[1;32m---> 25\u001b[0m     history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(x\u001b[38;5;241m=\u001b[39mnormal_trainset_1\u001b[38;5;241m.\u001b[39miloc[train_index], y\u001b[38;5;241m=\u001b[39my\u001b[38;5;241m.\u001b[39miloc[train_index], \n\u001b[0;32m     26\u001b[0m                        validation_data\u001b[38;5;241m=\u001b[39m(normal_trainset_1\u001b[38;5;241m.\u001b[39miloc[test_index], y\u001b[38;5;241m.\u001b[39miloc[test_index]),\n\u001b[0;32m     27\u001b[0m                        epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m     29\u001b[0m     history_list\u001b[38;5;241m.\u001b[39mappend(history)\n\u001b[0;32m     30\u001b[0m     trained_mlp\u001b[38;5;241m.\u001b[39mappend(model)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ARN\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ARN\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:323\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    321\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_epoch_begin(epoch)\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[1;32m--> 323\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    324\u001b[0m         callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m    325\u001b[0m         logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ARN\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:656\u001b[0m, in \u001b[0;36mTFEpochIterator.enumerate_epoch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    654\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_iterator\n\u001b[0;32m    655\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 656\u001b[0m     iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distributed_dataset)\n\u001b[0;32m    657\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_batches:\n\u001b[0;32m    658\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\n\u001b[0;32m    659\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_batches, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps_per_execution\n\u001b[0;32m    660\u001b[0m         ):\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ARN\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:501\u001b[0m, in \u001b[0;36mDatasetV2.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly() \u001b[38;5;129;01mor\u001b[39;00m ops\u001b[38;5;241m.\u001b[39minside_function():\n\u001b[0;32m    500\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[1;32m--> 501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m iterator_ops\u001b[38;5;241m.\u001b[39mOwnedIterator(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    502\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    503\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.Dataset` only supports Python-style \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    504\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miteration in eager mode or within tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ARN\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:705\u001b[0m, in \u001b[0;36mOwnedIterator.__init__\u001b[1;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[0;32m    701\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (components \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m element_spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    702\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    703\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `dataset` is provided, `element_spec` and `components` must \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    704\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot be specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 705\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_iterator(dataset)\n\u001b[0;32m    707\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_next_call_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ARN\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:744\u001b[0m, in \u001b[0;36mOwnedIterator._create_iterator\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    741\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fulltype\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\n\u001b[0;32m    742\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_output_types)\n\u001b[0;32m    743\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator_resource\u001b[38;5;241m.\u001b[39mop\u001b[38;5;241m.\u001b[39mexperimental_set_type(fulltype)\n\u001b[1;32m--> 744\u001b[0m gen_dataset_ops\u001b[38;5;241m.\u001b[39mmake_iterator(ds_variant, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator_resource)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\ARN\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3478\u001b[0m, in \u001b[0;36mmake_iterator\u001b[1;34m(dataset, iterator, name)\u001b[0m\n\u001b[0;32m   3476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m   3477\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3478\u001b[0m     _result \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_FastPathExecute(\n\u001b[0;32m   3479\u001b[0m       _ctx, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMakeIterator\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, dataset, iterator)\n\u001b[0;32m   3480\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   3481\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras import layers\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "import random as random\n",
    "# Programme principal de traitement du train set #1\n",
    "normal_trainset_1 = extract_features(trainset_1, 26)\n",
    "normal_trainset_1 = normalize(normal_trainset_1)\n",
    "normal_trainset_1 = normal_trainset_1.sample(frac=1, random_state=42)\n",
    "\n",
    "# splitting en 3 folds\n",
    "keras.utils.set_random_seed(123)\n",
    "kf = KFold(n_splits=3, shuffle=True)\n",
    "\n",
    "y = normal_trainset_1['state'].map({'w': 1, 'r': 0, 'n': 0})\n",
    "normal_trainset_1.drop(columns=['state'], inplace=True)\n",
    "history_list = []\n",
    "trained_mlp = []\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(normal_trainset_1)):\n",
    "    \n",
    "    model = create_model()\n",
    "    \n",
    "    history = model.fit(x=normal_trainset_1.iloc[train_index], y=y.iloc[train_index], \n",
    "                       validation_data=(normal_trainset_1.iloc[test_index], y.iloc[test_index]),\n",
    "                       epochs=100)\n",
    "    \n",
    "    history_list.append(history)\n",
    "    trained_mlp.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ec9f1513-f229-4f54-88d9-6ac7384620dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julien\\miniconda3\\envs\\ARN\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\Julien\\miniconda3\\envs\\ARN\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Julien\\miniconda3\\envs\\ARN\\Lib\\site-packages\\numpy\\core\\_methods.py:206: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\Julien\\miniconda3\\envs\\ARN\\Lib\\site-packages\\numpy\\core\\_methods.py:163: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "C:\\Users\\Julien\\miniconda3\\envs\\ARN\\Lib\\site-packages\\numpy\\core\\_methods.py:198: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'numpy.float64' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[155], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Plot mean and standard deviation for training loss\u001b[39;00m\n\u001b[0;32m     13\u001b[0m pl\u001b[38;5;241m.\u001b[39mplot(mean_train_loss, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Loss (Mean)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m pl\u001b[38;5;241m.\u001b[39mfill_between(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(mean_train_loss)), mean_train_loss \u001b[38;5;241m-\u001b[39m std_train_loss, mean_train_loss \u001b[38;5;241m+\u001b[39m std_train_loss, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Loss (Std)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Plot mean and standard deviation for validation loss\u001b[39;00m\n\u001b[0;32m     17\u001b[0m pl\u001b[38;5;241m.\u001b[39mplot(mean_val_loss, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation Loss (Mean)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'numpy.float64' has no len()"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "train_losses = np.array([history.history['loss'] for history in history_list])\n",
    "val_losses = np.array([history.history['val_loss'] for history in history_list])\n",
    "\n",
    "# Calculate mean and standard deviation for training and validation losses\n",
    "mean_train_loss = np.mean(train_losses, axis=0)\n",
    "std_train_loss = np.std(train_losses, axis=0)\n",
    "mean_val_loss = np.mean(val_losses, axis=0)\n",
    "std_val_loss = np.std(val_losses, axis=0)\n",
    "\n",
    "# Plot mean and standard deviation for training loss\n",
    "pl.plot(mean_train_loss, label='Training Loss (Mean)')\n",
    "pl.fill_between(range(len(mean_train_loss)), mean_train_loss - std_train_loss, mean_train_loss + std_train_loss, alpha=0.3, label='Training Loss (Std)')\n",
    "\n",
    "# Plot mean and standard deviation for validation loss\n",
    "pl.plot(mean_val_loss, label='Validation Loss (Mean)')\n",
    "pl.fill_between(range(len(mean_val_loss)), mean_val_loss - std_val_loss, mean_val_loss + std_val_loss, alpha=0.3, label='Validation Loss (Std)')\n",
    "\n",
    "# Add labels and legend\n",
    "pl.xlabel('Epochs')\n",
    "pl.ylabel('Loss')\n",
    "pl.legend()\n",
    "\n",
    "# Display the plot\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "5a7f4a4f-bd0e-42b6-ae7f-3a7f9320512d",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[156], line 20\u001b[0m\n\u001b[0;32m     16\u001b[0m mean_confusion_matrix \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (train_index, test_index) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(kf\u001b[38;5;241m.\u001b[39msplit(normal_trainset_1)):\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;66;03m# Evaluate the trained model on the test fold\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m (trained_mlp[i]\u001b[38;5;241m.\u001b[39mpredict(normal_trainset_1\u001b[38;5;241m.\u001b[39miloc[test_index]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m     21\u001b[0m     true_labels \u001b[38;5;241m=\u001b[39m (y\u001b[38;5;241m.\u001b[39miloc[test_index] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m# Compute confusion matrix\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_confusion_matrix(confusion_matrix, title):\n",
    "    # Plot confusion matrix\n",
    "    pl.figure(figsize=(8, 6))\n",
    "    sns.heatmap(confusion_matrix.astype(int), annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
    "                xticklabels=[\"r/nr\", \"w\"], yticklabels=[\"r/nr\", \"w\"])\n",
    "    pl.title(title)\n",
    "    pl.xlabel('Predicted')\n",
    "    pl.ylabel('True')\n",
    "    pl.show()\n",
    "\n",
    "f1_scores = []\n",
    "mean_confusion_matrix = np.zeros((2, 2))\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(normal_trainset_1)):\n",
    "    # Evaluate the trained model on the test fold\n",
    "    predictions = (trained_mlp[i].predict(normal_trainset_1.iloc[test_index]) > 0).astype(int)\n",
    "    true_labels = (y.iloc[test_index] > 0).astype(int)\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(true_labels, predictions)\n",
    "    mean_confusion_matrix += confusion_matrix(true_labels, predictions)\n",
    "\n",
    "    # Compute confusion matrix and plot\n",
    "    plot_confusion_matrix(cm, f'Confusion Matrix - Fold {i + 1}')\n",
    "\n",
    "    # Compute F1 score\n",
    "    f1 = f1_score(true_labels, predictions)\n",
    "    f1_scores.append(f1)\n",
    "    print(f\"F1 Score - Fold {i + 1}: {f1}\")\n",
    "\n",
    "# Plot mean confusion matrix\n",
    "plot_confusion_matrix(mean_confusion_matrix, 'Global confusion matrix')\n",
    "\n",
    "# Calculate and display the mean F1 score across all folds\n",
    "mean_f1_score = np.mean(f1_scores)\n",
    "print(f\"Mean F1 Score across all folds: {mean_f1_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad983335-0ef6-49bb-b4b8-3a98b5c6579f",
   "metadata": {},
   "source": [
    "# Entrainement du modèle avec 3 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "65fb46bb-ecca-4449-8c6a-0dc6c567298e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_17\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_17\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                      </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">        Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━┩\n",
       "│ dense_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                 │            <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │\n",
       "├───────────────────────────────────┼───────────────────────────┼────────────────┤\n",
       "│ dense_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span> │\n",
       "└───────────────────────────────────┴───────────────────────────┴────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━┩\n",
       "│ dense_34 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                 │            \u001b[38;5;34m130\u001b[0m │\n",
       "├───────────────────────────────────┼───────────────────────────┼────────────────┤\n",
       "│ dense_35 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                 │             \u001b[38;5;34m18\u001b[0m │\n",
       "└───────────────────────────────────┴───────────────────────────┴────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">148</span> (592.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m148\u001b[0m (592.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">148</span> (592.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m148\u001b[0m (592.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras import layers\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def create_model_three_class():\n",
    "  # 2 inputs\n",
    "  # 2 hidden nodes\n",
    "  # 1 output\n",
    "\n",
    "  mlp = keras.Sequential([\n",
    "      layers.Input(shape=(25,)),\n",
    "      layers.Dense(5, activation=\"tanh\"), # Try different numbers of hidden neurons here (e.g. 2, 4, 8, 32, 128)\n",
    "      layers.Dense(3, activation=\"tanh\"),\n",
    "  ])\n",
    "\n",
    "  # Experiment with hyperparameters here:\n",
    "  # momentum: [0, 0.8, 0.9, 0.99]\n",
    "  # learning_rate: [0.1, 0.01, 0.001, 0.0001]\n",
    "  mlp.compile(\n",
    "      optimizer=keras.optimizers.SGD(learning_rate=0.01, momentum=0.99),\n",
    "      loss=\"mse\",\n",
    "  )\n",
    "\n",
    "  return mlp\n",
    "mlp = create_model_three_class()\n",
    "mlp.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2da2b7-9f06-4d2e-8f9a-45069bafb399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.9515 - val_loss: 0.7065\n",
      "Epoch 2/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step - loss: 0.6826 - val_loss: 0.7057\n",
      "Epoch 3/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - loss: 0.6797 - val_loss: 0.7049\n",
      "Epoch 4/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6779 - val_loss: 0.7043\n",
      "Epoch 5/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6764 - val_loss: 0.7041\n",
      "Epoch 6/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6751 - val_loss: 0.7042\n",
      "Epoch 7/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6744 - val_loss: 0.7037\n",
      "Epoch 8/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6739 - val_loss: 0.7040\n",
      "Epoch 9/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - loss: 0.6736 - val_loss: 0.7039\n",
      "Epoch 10/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 990us/step - loss: 0.6731 - val_loss: 0.7042\n",
      "Epoch 11/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6727 - val_loss: 0.7041\n",
      "Epoch 12/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6724 - val_loss: 0.7041\n",
      "Epoch 13/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6726 - val_loss: 0.7045\n",
      "Epoch 14/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6724 - val_loss: 0.7047\n",
      "Epoch 15/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6720 - val_loss: 0.7045\n",
      "Epoch 16/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6717 - val_loss: 0.7045\n",
      "Epoch 17/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6713 - val_loss: 0.7047\n",
      "Epoch 18/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6709 - val_loss: 0.7047\n",
      "Epoch 19/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6705 - val_loss: 0.7047\n",
      "Epoch 20/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6701 - val_loss: 0.7048\n",
      "Epoch 21/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6698 - val_loss: 0.7050\n",
      "Epoch 22/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6696 - val_loss: 0.7052\n",
      "Epoch 23/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6694 - val_loss: 0.7052\n",
      "Epoch 24/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6692 - val_loss: 0.7053\n",
      "Epoch 25/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6691 - val_loss: 0.7052\n",
      "Epoch 26/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6688 - val_loss: 0.7052\n",
      "Epoch 27/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6688 - val_loss: 0.7051\n",
      "Epoch 28/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6686 - val_loss: 0.7048\n",
      "Epoch 29/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6684 - val_loss: 0.7045\n",
      "Epoch 30/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6683 - val_loss: 0.7045\n",
      "Epoch 31/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6682 - val_loss: 0.7046\n",
      "Epoch 32/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6682 - val_loss: 0.7047\n",
      "Epoch 33/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6681 - val_loss: 0.7048\n",
      "Epoch 34/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6680 - val_loss: 0.7045\n",
      "Epoch 35/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6680 - val_loss: 0.7050\n",
      "Epoch 36/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6679 - val_loss: 0.7047\n",
      "Epoch 37/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6679 - val_loss: 0.7045\n",
      "Epoch 38/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6680 - val_loss: 0.7048\n",
      "Epoch 39/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6677 - val_loss: 0.7047\n",
      "Epoch 40/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6675 - val_loss: 0.7045\n",
      "Epoch 41/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6675 - val_loss: 0.7046\n",
      "Epoch 42/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6673 - val_loss: 0.7044\n",
      "Epoch 43/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6671 - val_loss: 0.7040\n",
      "Epoch 44/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6667 - val_loss: 0.7037\n",
      "Epoch 45/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6666 - val_loss: 0.7041\n",
      "Epoch 46/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6663 - val_loss: 0.7040\n",
      "Epoch 47/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6662 - val_loss: 0.7039\n",
      "Epoch 48/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6661 - val_loss: 0.7038\n",
      "Epoch 49/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6661 - val_loss: 0.7039\n",
      "Epoch 50/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6658 - val_loss: 0.7039\n",
      "Epoch 51/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6658 - val_loss: 0.7041\n",
      "Epoch 52/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6657 - val_loss: 0.7041\n",
      "Epoch 53/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6657 - val_loss: 0.7042\n",
      "Epoch 54/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6656 - val_loss: 0.7043\n",
      "Epoch 55/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6656 - val_loss: 0.7044\n",
      "Epoch 56/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - loss: 0.6656 - val_loss: 0.7045\n",
      "Epoch 57/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6656 - val_loss: 0.7046\n",
      "Epoch 58/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6655 - val_loss: 0.7046\n",
      "Epoch 59/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6655 - val_loss: 0.7048\n",
      "Epoch 60/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6654 - val_loss: 0.7048\n",
      "Epoch 61/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6654 - val_loss: 0.7052\n",
      "Epoch 62/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6654 - val_loss: 0.7052\n",
      "Epoch 63/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6654 - val_loss: 0.7055\n",
      "Epoch 64/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6654 - val_loss: 0.7055\n",
      "Epoch 65/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step - loss: 0.6654 - val_loss: 0.7059\n",
      "Epoch 66/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6653 - val_loss: 0.7059\n",
      "Epoch 67/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6653 - val_loss: 0.7062\n",
      "Epoch 68/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6653 - val_loss: 0.7061\n",
      "Epoch 69/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6653 - val_loss: 0.7064\n",
      "Epoch 70/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6652 - val_loss: 0.7062\n",
      "Epoch 71/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6652 - val_loss: 0.7065\n",
      "Epoch 72/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6652 - val_loss: 0.7063\n",
      "Epoch 73/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6652 - val_loss: 0.7066\n",
      "Epoch 74/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - loss: 0.6651 - val_loss: 0.7063\n",
      "Epoch 75/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6651 - val_loss: 0.7066\n",
      "Epoch 76/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6650 - val_loss: 0.7064\n",
      "Epoch 77/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6650 - val_loss: 0.7067\n",
      "Epoch 78/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6650 - val_loss: 0.7065\n",
      "Epoch 79/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6650 - val_loss: 0.7068\n",
      "Epoch 80/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6649 - val_loss: 0.7065\n",
      "Epoch 81/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6650 - val_loss: 0.7068\n",
      "Epoch 82/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6649 - val_loss: 0.7066\n",
      "Epoch 83/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6649 - val_loss: 0.7069\n",
      "Epoch 84/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6649 - val_loss: 0.7067\n",
      "Epoch 85/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - loss: 0.6649 - val_loss: 0.7070\n",
      "Epoch 86/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6648 - val_loss: 0.7067\n",
      "Epoch 87/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6648 - val_loss: 0.7070\n",
      "Epoch 88/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6648 - val_loss: 0.7068\n",
      "Epoch 89/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6648 - val_loss: 0.7071\n",
      "Epoch 90/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6647 - val_loss: 0.7069\n",
      "Epoch 91/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6647 - val_loss: 0.7072\n",
      "Epoch 92/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6647 - val_loss: 0.7070\n",
      "Epoch 93/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6647 - val_loss: 0.7073\n",
      "Epoch 94/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6647 - val_loss: 0.7070\n",
      "Epoch 95/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6647 - val_loss: 0.7073\n",
      "Epoch 96/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6646 - val_loss: 0.7071\n",
      "Epoch 97/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6646 - val_loss: 0.7074\n",
      "Epoch 98/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6646 - val_loss: 0.7071\n",
      "Epoch 99/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6646 - val_loss: 0.7074\n",
      "Epoch 100/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6646 - val_loss: 0.7072\n",
      "Epoch 101/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6646 - val_loss: 0.7075\n",
      "Epoch 102/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6645 - val_loss: 0.7073\n",
      "Epoch 103/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6646 - val_loss: 0.7075\n",
      "Epoch 104/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6645 - val_loss: 0.7073\n",
      "Epoch 105/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step - loss: 0.6645 - val_loss: 0.7076\n",
      "Epoch 106/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6645 - val_loss: 0.7074\n",
      "Epoch 107/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6645 - val_loss: 0.7076\n",
      "Epoch 108/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6645 - val_loss: 0.7074\n",
      "Epoch 109/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6645 - val_loss: 0.7077\n",
      "Epoch 110/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6644 - val_loss: 0.7074\n",
      "Epoch 111/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - loss: 0.6645 - val_loss: 0.7077\n",
      "Epoch 112/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6644 - val_loss: 0.7075\n",
      "Epoch 113/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6645 - val_loss: 0.7077\n",
      "Epoch 114/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6644 - val_loss: 0.7075\n",
      "Epoch 115/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6645 - val_loss: 0.7077\n",
      "Epoch 116/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6644 - val_loss: 0.7075\n",
      "Epoch 117/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6645 - val_loss: 0.7078\n",
      "Epoch 118/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6643 - val_loss: 0.7076\n",
      "Epoch 119/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6644 - val_loss: 0.7078\n",
      "Epoch 120/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6643 - val_loss: 0.7076\n",
      "Epoch 121/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6644 - val_loss: 0.7078\n",
      "Epoch 122/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6643 - val_loss: 0.7076\n",
      "Epoch 123/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6644 - val_loss: 0.7078\n",
      "Epoch 124/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6642 - val_loss: 0.7077\n",
      "Epoch 125/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6643 - val_loss: 0.7078\n",
      "Epoch 126/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6642 - val_loss: 0.7077\n",
      "Epoch 127/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6643 - val_loss: 0.7078\n",
      "Epoch 128/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6642 - val_loss: 0.7077\n",
      "Epoch 129/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6643 - val_loss: 0.7078\n",
      "Epoch 130/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6642 - val_loss: 0.7077\n",
      "Epoch 131/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6643 - val_loss: 0.7078\n",
      "Epoch 132/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6641 - val_loss: 0.7077\n",
      "Epoch 133/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6642 - val_loss: 0.7078\n",
      "Epoch 134/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6641 - val_loss: 0.7076\n",
      "Epoch 135/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6642 - val_loss: 0.7078\n",
      "Epoch 136/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6641 - val_loss: 0.7077\n",
      "Epoch 137/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6642 - val_loss: 0.7078\n",
      "Epoch 138/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6640 - val_loss: 0.7077\n",
      "Epoch 139/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6642 - val_loss: 0.7079\n",
      "Epoch 140/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6640 - val_loss: 0.7077\n",
      "Epoch 141/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6641 - val_loss: 0.7079\n",
      "Epoch 142/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6640 - val_loss: 0.7078\n",
      "Epoch 143/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6641 - val_loss: 0.7079\n",
      "Epoch 144/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6640 - val_loss: 0.7078\n",
      "Epoch 145/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6641 - val_loss: 0.7079\n",
      "Epoch 146/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6640 - val_loss: 0.7078\n",
      "Epoch 147/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6641 - val_loss: 0.7079\n",
      "Epoch 148/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6639 - val_loss: 0.7078\n",
      "Epoch 149/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6640 - val_loss: 0.7079\n",
      "Epoch 150/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6639 - val_loss: 0.7078\n",
      "Epoch 151/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6640 - val_loss: 0.7080\n",
      "Epoch 152/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6639 - val_loss: 0.7079\n",
      "Epoch 153/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6640 - val_loss: 0.7080\n",
      "Epoch 154/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6639 - val_loss: 0.7079\n",
      "Epoch 155/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 990us/step - loss: 0.6640 - val_loss: 0.7080\n",
      "Epoch 156/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6639 - val_loss: 0.7079\n",
      "Epoch 157/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6639 - val_loss: 0.7080\n",
      "Epoch 158/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6638 - val_loss: 0.7080\n",
      "Epoch 159/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6639 - val_loss: 0.7081\n",
      "Epoch 160/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6638 - val_loss: 0.7080\n",
      "Epoch 161/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6639 - val_loss: 0.7081\n",
      "Epoch 162/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6638 - val_loss: 0.7080\n",
      "Epoch 163/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6639 - val_loss: 0.7081\n",
      "Epoch 164/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6638 - val_loss: 0.7081\n",
      "Epoch 165/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6639 - val_loss: 0.7082\n",
      "Epoch 166/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6638 - val_loss: 0.7081\n",
      "Epoch 167/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6639 - val_loss: 0.7082\n",
      "Epoch 168/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6638 - val_loss: 0.7082\n",
      "Epoch 169/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6639 - val_loss: 0.7083\n",
      "Epoch 170/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6638 - val_loss: 0.7082\n",
      "Epoch 171/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6638 - val_loss: 0.7083\n",
      "Epoch 172/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6637 - val_loss: 0.7083\n",
      "Epoch 173/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6638 - val_loss: 0.7084\n",
      "Epoch 174/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6637 - val_loss: 0.7083\n",
      "Epoch 175/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6638 - val_loss: 0.7084\n",
      "Epoch 176/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6637 - val_loss: 0.7084\n",
      "Epoch 177/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6638 - val_loss: 0.7085\n",
      "Epoch 178/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6637 - val_loss: 0.7085\n",
      "Epoch 179/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6638 - val_loss: 0.7085\n",
      "Epoch 180/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6637 - val_loss: 0.7085\n",
      "Epoch 181/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6638 - val_loss: 0.7085\n",
      "Epoch 182/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6637 - val_loss: 0.7086\n",
      "Epoch 183/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6637 - val_loss: 0.7085\n",
      "Epoch 184/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6637 - val_loss: 0.7086\n",
      "Epoch 185/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6637 - val_loss: 0.7086\n",
      "Epoch 186/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6637 - val_loss: 0.7086\n",
      "Epoch 187/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6637 - val_loss: 0.7086\n",
      "Epoch 188/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6636 - val_loss: 0.7086\n",
      "Epoch 189/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6637 - val_loss: 0.7086\n",
      "Epoch 190/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6636 - val_loss: 0.7086\n",
      "Epoch 191/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6637 - val_loss: 0.7086\n",
      "Epoch 192/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6636 - val_loss: 0.7086\n",
      "Epoch 193/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6636 - val_loss: 0.7086\n",
      "Epoch 194/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6636 - val_loss: 0.7086\n",
      "Epoch 195/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6636 - val_loss: 0.7086\n",
      "Epoch 196/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6635 - val_loss: 0.7086\n",
      "Epoch 197/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6636 - val_loss: 0.7086\n",
      "Epoch 198/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6635 - val_loss: 0.7086\n",
      "Epoch 199/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6636 - val_loss: 0.7086\n",
      "Epoch 200/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6635 - val_loss: 0.7086\n",
      "Epoch 201/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6635 - val_loss: 0.7086\n",
      "Epoch 202/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6635 - val_loss: 0.7086\n",
      "Epoch 203/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6635 - val_loss: 0.7086\n",
      "Epoch 204/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6635 - val_loss: 0.7086\n",
      "Epoch 205/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6635 - val_loss: 0.7086\n",
      "Epoch 206/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6634 - val_loss: 0.7086\n",
      "Epoch 207/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6635 - val_loss: 0.7087\n",
      "Epoch 208/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6634 - val_loss: 0.7086\n",
      "Epoch 209/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6634 - val_loss: 0.7086\n",
      "Epoch 210/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6634 - val_loss: 0.7087\n",
      "Epoch 211/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6634 - val_loss: 0.7086\n",
      "Epoch 212/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6634 - val_loss: 0.7087\n",
      "Epoch 213/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6634 - val_loss: 0.7087\n",
      "Epoch 214/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6633 - val_loss: 0.7086\n",
      "Epoch 215/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6634 - val_loss: 0.7087\n",
      "Epoch 216/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6633 - val_loss: 0.7086\n",
      "Epoch 217/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6633 - val_loss: 0.7087\n",
      "Epoch 218/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6633 - val_loss: 0.7087\n",
      "Epoch 219/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6633 - val_loss: 0.7086\n",
      "Epoch 220/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6633 - val_loss: 0.7087\n",
      "Epoch 221/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6633 - val_loss: 0.7086\n",
      "Epoch 222/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6632 - val_loss: 0.7087\n",
      "Epoch 223/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6632 - val_loss: 0.7087\n",
      "Epoch 224/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6632 - val_loss: 0.7086\n",
      "Epoch 225/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6632 - val_loss: 0.7087\n",
      "Epoch 226/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6632 - val_loss: 0.7087\n",
      "Epoch 227/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6632 - val_loss: 0.7087\n",
      "Epoch 228/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6631 - val_loss: 0.7087\n",
      "Epoch 229/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6631 - val_loss: 0.7087\n",
      "Epoch 230/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6631 - val_loss: 0.7087\n",
      "Epoch 231/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6631 - val_loss: 0.7087\n",
      "Epoch 232/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6631 - val_loss: 0.7087\n",
      "Epoch 233/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6631 - val_loss: 0.7087\n",
      "Epoch 234/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6631 - val_loss: 0.7087\n",
      "Epoch 235/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6631 - val_loss: 0.7087\n",
      "Epoch 236/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6631 - val_loss: 0.7087\n",
      "Epoch 237/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6631 - val_loss: 0.7087\n",
      "Epoch 238/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6630 - val_loss: 0.7087\n",
      "Epoch 239/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6630 - val_loss: 0.7087\n",
      "Epoch 240/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6630 - val_loss: 0.7087\n",
      "Epoch 241/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6630 - val_loss: 0.7087\n",
      "Epoch 242/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6630 - val_loss: 0.7087\n",
      "Epoch 243/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6630 - val_loss: 0.7088\n",
      "Epoch 244/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6630 - val_loss: 0.7087\n",
      "Epoch 245/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6630 - val_loss: 0.7088\n",
      "Epoch 246/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6630 - val_loss: 0.7087\n",
      "Epoch 247/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6630 - val_loss: 0.7087\n",
      "Epoch 248/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6630 - val_loss: 0.7088\n",
      "Epoch 249/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6630 - val_loss: 0.7087\n",
      "Epoch 250/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6629 - val_loss: 0.7088\n",
      "Epoch 251/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6630 - val_loss: 0.7088\n",
      "Epoch 252/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6629 - val_loss: 0.7087\n",
      "Epoch 253/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6629 - val_loss: 0.7088\n",
      "Epoch 254/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6629 - val_loss: 0.7087\n",
      "Epoch 255/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6629 - val_loss: 0.7088\n",
      "Epoch 256/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6629 - val_loss: 0.7088\n",
      "Epoch 257/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6629 - val_loss: 0.7088\n",
      "Epoch 258/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6629 - val_loss: 0.7088\n",
      "Epoch 259/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6629 - val_loss: 0.7088\n",
      "Epoch 260/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6629 - val_loss: 0.7088\n",
      "Epoch 261/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6629 - val_loss: 0.7088\n",
      "Epoch 262/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6629 - val_loss: 0.7088\n",
      "Epoch 263/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6629 - val_loss: 0.7088\n",
      "Epoch 264/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6629 - val_loss: 0.7088\n",
      "Epoch 265/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6629 - val_loss: 0.7088\n",
      "Epoch 266/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6628 - val_loss: 0.7088\n",
      "Epoch 267/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6629 - val_loss: 0.7088\n",
      "Epoch 268/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6628 - val_loss: 0.7088\n",
      "Epoch 269/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6628 - val_loss: 0.7088\n",
      "Epoch 270/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6628 - val_loss: 0.7088\n",
      "Epoch 271/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6628 - val_loss: 0.7088\n",
      "Epoch 272/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6628 - val_loss: 0.7088\n",
      "Epoch 273/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6628 - val_loss: 0.7088\n",
      "Epoch 274/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6628 - val_loss: 0.7088\n",
      "Epoch 275/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6628 - val_loss: 0.7088\n",
      "Epoch 276/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6628 - val_loss: 0.7088\n",
      "Epoch 277/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6628 - val_loss: 0.7088\n",
      "Epoch 278/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6628 - val_loss: 0.7088\n",
      "Epoch 279/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6628 - val_loss: 0.7088\n",
      "Epoch 280/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6628 - val_loss: 0.7088\n",
      "Epoch 281/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6628 - val_loss: 0.7089\n",
      "Epoch 282/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6628 - val_loss: 0.7088\n",
      "Epoch 283/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6628 - val_loss: 0.7089\n",
      "Epoch 284/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6627 - val_loss: 0.7088\n",
      "Epoch 285/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6627 - val_loss: 0.7088\n",
      "Epoch 286/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6627 - val_loss: 0.7089\n",
      "Epoch 287/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6627 - val_loss: 0.7088\n",
      "Epoch 288/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6627 - val_loss: 0.7089\n",
      "Epoch 289/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6627 - val_loss: 0.7089\n",
      "Epoch 290/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6627 - val_loss: 0.7088\n",
      "Epoch 291/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6627 - val_loss: 0.7089\n",
      "Epoch 292/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6627 - val_loss: 0.7088\n",
      "Epoch 293/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6627 - val_loss: 0.7089\n",
      "Epoch 294/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6627 - val_loss: 0.7089\n",
      "Epoch 295/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6627 - val_loss: 0.7089\n",
      "Epoch 296/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6627 - val_loss: 0.7089\n",
      "Epoch 297/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6627 - val_loss: 0.7089\n",
      "Epoch 298/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6627 - val_loss: 0.7089\n",
      "Epoch 299/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6627 - val_loss: 0.7089\n",
      "Epoch 300/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6627 - val_loss: 0.7089\n",
      "Epoch 1/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9410 - val_loss: 0.6942\n",
      "Epoch 2/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.7043 - val_loss: 0.6920\n",
      "Epoch 3/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.7011 - val_loss: 0.6967\n",
      "Epoch 4/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6986 - val_loss: 0.6994\n",
      "Epoch 5/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6980 - val_loss: 0.7001\n",
      "Epoch 6/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6963 - val_loss: 0.6984\n",
      "Epoch 7/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6928 - val_loss: 0.6986\n",
      "Epoch 8/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6933 - val_loss: 0.6991\n",
      "Epoch 9/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6922 - val_loss: 0.6991\n",
      "Epoch 10/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6914 - val_loss: 0.7007\n",
      "Epoch 11/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6918 - val_loss: 0.7019\n",
      "Epoch 12/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6915 - val_loss: 0.7020\n",
      "Epoch 13/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6914 - val_loss: 0.7032\n",
      "Epoch 14/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6914 - val_loss: 0.7023\n",
      "Epoch 15/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6915 - val_loss: 0.7042\n",
      "Epoch 16/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6914 - val_loss: 0.7029\n",
      "Epoch 17/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6915 - val_loss: 0.7045\n",
      "Epoch 18/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6911 - val_loss: 0.7039\n",
      "Epoch 19/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6908 - val_loss: 0.7036\n",
      "Epoch 20/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6907 - val_loss: 0.7042\n",
      "Epoch 21/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6911 - val_loss: 0.7037\n",
      "Epoch 22/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6905 - val_loss: 0.7027\n",
      "Epoch 23/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6902 - val_loss: 0.7019\n",
      "Epoch 24/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6895 - val_loss: 0.7013\n",
      "Epoch 25/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6896 - val_loss: 0.7030\n",
      "Epoch 26/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6895 - val_loss: 0.7008\n",
      "Epoch 27/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6889 - val_loss: 0.7017\n",
      "Epoch 28/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6892 - val_loss: 0.7000\n",
      "Epoch 29/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6888 - val_loss: 0.7031\n",
      "Epoch 30/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6900 - val_loss: 0.7037\n",
      "Epoch 31/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6890 - val_loss: 0.7021\n",
      "Epoch 32/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6888 - val_loss: 0.7034\n",
      "Epoch 33/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6888 - val_loss: 0.7015\n",
      "Epoch 34/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6883 - val_loss: 0.7035\n",
      "Epoch 35/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6884 - val_loss: 0.7025\n",
      "Epoch 36/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6884 - val_loss: 0.7031\n",
      "Epoch 37/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6880 - val_loss: 0.7024\n",
      "Epoch 38/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6882 - val_loss: 0.7036\n",
      "Epoch 39/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6881 - val_loss: 0.7025\n",
      "Epoch 40/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6880 - val_loss: 0.7043\n",
      "Epoch 41/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6883 - val_loss: 0.7028\n",
      "Epoch 42/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6879 - val_loss: 0.7037\n",
      "Epoch 43/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6879 - val_loss: 0.7030\n",
      "Epoch 44/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6878 - val_loss: 0.7040\n",
      "Epoch 45/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6877 - val_loss: 0.7028\n",
      "Epoch 46/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6875 - val_loss: 0.7043\n",
      "Epoch 47/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6880 - val_loss: 0.7030\n",
      "Epoch 48/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6875 - val_loss: 0.7043\n",
      "Epoch 49/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6877 - val_loss: 0.7031\n",
      "Epoch 50/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6874 - val_loss: 0.7041\n",
      "Epoch 51/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6877 - val_loss: 0.7030\n",
      "Epoch 52/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6874 - val_loss: 0.7043\n",
      "Epoch 53/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6875 - val_loss: 0.7031\n",
      "Epoch 54/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6873 - val_loss: 0.7043\n",
      "Epoch 55/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6877 - val_loss: 0.7034\n",
      "Epoch 56/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6873 - val_loss: 0.7042\n",
      "Epoch 57/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6876 - val_loss: 0.7037\n",
      "Epoch 58/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6873 - val_loss: 0.7045\n",
      "Epoch 59/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6874 - val_loss: 0.7038\n",
      "Epoch 60/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6872 - val_loss: 0.7046\n",
      "Epoch 61/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6873 - val_loss: 0.7037\n",
      "Epoch 62/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6871 - val_loss: 0.7044\n",
      "Epoch 63/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6874 - val_loss: 0.7040\n",
      "Epoch 64/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6870 - val_loss: 0.7047\n",
      "Epoch 65/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6873 - val_loss: 0.7040\n",
      "Epoch 66/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6868 - val_loss: 0.7046\n",
      "Epoch 67/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6870 - val_loss: 0.7046\n",
      "Epoch 68/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6869 - val_loss: 0.7047\n",
      "Epoch 69/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6870 - val_loss: 0.7041\n",
      "Epoch 70/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6866 - val_loss: 0.7046\n",
      "Epoch 71/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6868 - val_loss: 0.7044\n",
      "Epoch 72/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6867 - val_loss: 0.7043\n",
      "Epoch 73/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6867 - val_loss: 0.7040\n",
      "Epoch 74/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6867 - val_loss: 0.7050\n",
      "Epoch 75/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6867 - val_loss: 0.7045\n",
      "Epoch 76/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6868 - val_loss: 0.7046\n",
      "Epoch 77/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6867 - val_loss: 0.7040\n",
      "Epoch 78/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6868 - val_loss: 0.7040\n",
      "Epoch 79/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6868 - val_loss: 0.7050\n",
      "Epoch 80/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6866 - val_loss: 0.7039\n",
      "Epoch 81/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6862 - val_loss: 0.7041\n",
      "Epoch 82/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6864 - val_loss: 0.7042\n",
      "Epoch 83/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6869 - val_loss: 0.7037\n",
      "Epoch 84/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6864 - val_loss: 0.7044\n",
      "Epoch 85/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6863 - val_loss: 0.7046\n",
      "Epoch 86/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6863 - val_loss: 0.7041\n",
      "Epoch 87/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6862 - val_loss: 0.7036\n",
      "Epoch 88/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6864 - val_loss: 0.7042\n",
      "Epoch 89/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6862 - val_loss: 0.7035\n",
      "Epoch 90/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6862 - val_loss: 0.7038\n",
      "Epoch 91/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6863 - val_loss: 0.7034\n",
      "Epoch 92/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6862 - val_loss: 0.7038\n",
      "Epoch 93/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6864 - val_loss: 0.7027\n",
      "Epoch 94/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6858 - val_loss: 0.7047\n",
      "Epoch 95/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6863 - val_loss: 0.7033\n",
      "Epoch 96/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6863 - val_loss: 0.7039\n",
      "Epoch 97/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6859 - val_loss: 0.7037\n",
      "Epoch 98/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6863 - val_loss: 0.7051\n",
      "Epoch 99/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6863 - val_loss: 0.7043\n",
      "Epoch 100/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6861 - val_loss: 0.7029\n",
      "Epoch 101/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6861 - val_loss: 0.7051\n",
      "Epoch 102/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6861 - val_loss: 0.7039\n",
      "Epoch 103/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6860 - val_loss: 0.7039\n",
      "Epoch 104/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6861 - val_loss: 0.7037\n",
      "Epoch 105/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6862 - val_loss: 0.7033\n",
      "Epoch 106/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6859 - val_loss: 0.7045\n",
      "Epoch 107/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6861 - val_loss: 0.7043\n",
      "Epoch 108/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6862 - val_loss: 0.7044\n",
      "Epoch 109/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6861 - val_loss: 0.7035\n",
      "Epoch 110/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6865 - val_loss: 0.7045\n",
      "Epoch 111/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6862 - val_loss: 0.7042\n",
      "Epoch 112/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6862 - val_loss: 0.7047\n",
      "Epoch 113/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6859 - val_loss: 0.7039\n",
      "Epoch 114/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6861 - val_loss: 0.7049\n",
      "Epoch 115/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6862 - val_loss: 0.7037\n",
      "Epoch 116/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6863 - val_loss: 0.7054\n",
      "Epoch 117/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6863 - val_loss: 0.7037\n",
      "Epoch 118/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6862 - val_loss: 0.7038\n",
      "Epoch 119/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6866 - val_loss: 0.7052\n",
      "Epoch 120/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6860 - val_loss: 0.7040\n",
      "Epoch 121/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6864 - val_loss: 0.7048\n",
      "Epoch 122/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6859 - val_loss: 0.7044\n",
      "Epoch 123/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6862 - val_loss: 0.7052\n",
      "Epoch 124/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6859 - val_loss: 0.7041\n",
      "Epoch 125/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6860 - val_loss: 0.7045\n",
      "Epoch 126/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6858 - val_loss: 0.7042\n",
      "Epoch 127/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6858 - val_loss: 0.7050\n",
      "Epoch 128/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6857 - val_loss: 0.7047\n",
      "Epoch 129/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6856 - val_loss: 0.7038\n",
      "Epoch 130/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6861 - val_loss: 0.7052\n",
      "Epoch 131/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6861 - val_loss: 0.7037\n",
      "Epoch 132/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6860 - val_loss: 0.7048\n",
      "Epoch 133/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6859 - val_loss: 0.7049\n",
      "Epoch 134/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6859 - val_loss: 0.7040\n",
      "Epoch 135/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6859 - val_loss: 0.7040\n",
      "Epoch 136/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6858 - val_loss: 0.7038\n",
      "Epoch 137/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6858 - val_loss: 0.7046\n",
      "Epoch 138/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6858 - val_loss: 0.7048\n",
      "Epoch 139/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6859 - val_loss: 0.7043\n",
      "Epoch 140/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6857 - val_loss: 0.7044\n",
      "Epoch 141/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6859 - val_loss: 0.7045\n",
      "Epoch 142/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6858 - val_loss: 0.7043\n",
      "Epoch 143/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6860 - val_loss: 0.7043\n",
      "Epoch 144/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6860 - val_loss: 0.7046\n",
      "Epoch 145/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6859 - val_loss: 0.7042\n",
      "Epoch 146/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6857 - val_loss: 0.7043\n",
      "Epoch 147/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6860 - val_loss: 0.7040\n",
      "Epoch 148/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6859 - val_loss: 0.7047\n",
      "Epoch 149/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6858 - val_loss: 0.7042\n",
      "Epoch 150/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6857 - val_loss: 0.7042\n",
      "Epoch 151/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6860 - val_loss: 0.7045\n",
      "Epoch 152/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6857 - val_loss: 0.7046\n",
      "Epoch 153/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6857 - val_loss: 0.7045\n",
      "Epoch 154/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6858 - val_loss: 0.7047\n",
      "Epoch 155/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6859 - val_loss: 0.7039\n",
      "Epoch 156/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6860 - val_loss: 0.7042\n",
      "Epoch 157/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6858 - val_loss: 0.7041\n",
      "Epoch 158/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6859 - val_loss: 0.7042\n",
      "Epoch 159/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6856 - val_loss: 0.7047\n",
      "Epoch 160/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6858 - val_loss: 0.7052\n",
      "Epoch 161/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6857 - val_loss: 0.7049\n",
      "Epoch 162/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6858 - val_loss: 0.7049\n",
      "Epoch 163/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6858 - val_loss: 0.7042\n",
      "Epoch 164/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6858 - val_loss: 0.7037\n",
      "Epoch 165/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6855 - val_loss: 0.7048\n",
      "Epoch 166/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6858 - val_loss: 0.7046\n",
      "Epoch 167/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6856 - val_loss: 0.7047\n",
      "Epoch 168/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6857 - val_loss: 0.7049\n",
      "Epoch 169/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6856 - val_loss: 0.7042\n",
      "Epoch 170/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6859 - val_loss: 0.7058\n",
      "Epoch 171/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6858 - val_loss: 0.7041\n",
      "Epoch 172/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6858 - val_loss: 0.7044\n",
      "Epoch 173/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6858 - val_loss: 0.7044\n",
      "Epoch 174/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6853 - val_loss: 0.7043\n",
      "Epoch 175/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6858 - val_loss: 0.7047\n",
      "Epoch 176/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6857 - val_loss: 0.7047\n",
      "Epoch 177/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6858 - val_loss: 0.7049\n",
      "Epoch 178/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6857 - val_loss: 0.7042\n",
      "Epoch 179/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6860 - val_loss: 0.7052\n",
      "Epoch 180/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6858 - val_loss: 0.7039\n",
      "Epoch 181/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6857 - val_loss: 0.7049\n",
      "Epoch 182/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6854 - val_loss: 0.7047\n",
      "Epoch 183/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6859 - val_loss: 0.7059\n",
      "Epoch 184/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6859 - val_loss: 0.7045\n",
      "Epoch 185/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6860 - val_loss: 0.7057\n",
      "Epoch 186/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6859 - val_loss: 0.7045\n",
      "Epoch 187/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6856 - val_loss: 0.7054\n",
      "Epoch 188/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6859 - val_loss: 0.7049\n",
      "Epoch 189/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.6855 - val_loss: 0.7048\n",
      "Epoch 190/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6857 - val_loss: 0.7047\n",
      "Epoch 191/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6856 - val_loss: 0.7051\n",
      "Epoch 192/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6854 - val_loss: 0.7053\n",
      "Epoch 193/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.6858 - val_loss: 0.7051\n",
      "Epoch 194/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6857 - val_loss: 0.7046\n",
      "Epoch 195/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6856 - val_loss: 0.7053\n",
      "Epoch 196/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6858 - val_loss: 0.7048\n",
      "Epoch 197/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6855 - val_loss: 0.7052\n",
      "Epoch 198/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6857 - val_loss: 0.7052\n",
      "Epoch 199/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6855 - val_loss: 0.7054\n",
      "Epoch 200/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6858 - val_loss: 0.7042\n",
      "Epoch 201/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6856 - val_loss: 0.7053\n",
      "Epoch 202/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6856 - val_loss: 0.7044\n",
      "Epoch 203/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6854 - val_loss: 0.7059\n",
      "Epoch 204/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6858 - val_loss: 0.7049\n",
      "Epoch 205/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6857 - val_loss: 0.7048\n",
      "Epoch 206/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6856 - val_loss: 0.7054\n",
      "Epoch 207/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6857 - val_loss: 0.7050\n",
      "Epoch 208/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6854 - val_loss: 0.7050\n",
      "Epoch 209/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6858 - val_loss: 0.7054\n",
      "Epoch 210/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6856 - val_loss: 0.7054\n",
      "Epoch 211/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6859 - val_loss: 0.7059\n",
      "Epoch 212/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6856 - val_loss: 0.7055\n",
      "Epoch 213/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6857 - val_loss: 0.7053\n",
      "Epoch 214/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6855 - val_loss: 0.7053\n",
      "Epoch 215/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6859 - val_loss: 0.7054\n",
      "Epoch 216/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6855 - val_loss: 0.7064\n",
      "Epoch 217/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6856 - val_loss: 0.7059\n",
      "Epoch 218/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6859 - val_loss: 0.7074\n",
      "Epoch 219/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6857 - val_loss: 0.7047\n",
      "Epoch 220/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6857 - val_loss: 0.7069\n",
      "Epoch 221/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6856 - val_loss: 0.7067\n",
      "Epoch 222/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6856 - val_loss: 0.7063\n",
      "Epoch 223/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6855 - val_loss: 0.7064\n",
      "Epoch 224/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6853 - val_loss: 0.7054\n",
      "Epoch 225/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6857 - val_loss: 0.7067\n",
      "Epoch 226/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6856 - val_loss: 0.7062\n",
      "Epoch 227/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6855 - val_loss: 0.7048\n",
      "Epoch 228/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6857 - val_loss: 0.7069\n",
      "Epoch 229/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6855 - val_loss: 0.7055\n",
      "Epoch 230/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6858 - val_loss: 0.7061\n",
      "Epoch 231/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6859 - val_loss: 0.7050\n",
      "Epoch 232/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6855 - val_loss: 0.7058\n",
      "Epoch 233/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6858 - val_loss: 0.7063\n",
      "Epoch 234/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6855 - val_loss: 0.7060\n",
      "Epoch 235/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6856 - val_loss: 0.7057\n",
      "Epoch 236/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6855 - val_loss: 0.7068\n",
      "Epoch 237/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6859 - val_loss: 0.7061\n",
      "Epoch 238/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6855 - val_loss: 0.7048\n",
      "Epoch 239/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6853 - val_loss: 0.7062\n",
      "Epoch 240/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6850 - val_loss: 0.7052\n",
      "Epoch 241/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6857 - val_loss: 0.7068\n",
      "Epoch 242/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6850 - val_loss: 0.7054\n",
      "Epoch 243/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6856 - val_loss: 0.7063\n",
      "Epoch 244/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6855 - val_loss: 0.7060\n",
      "Epoch 245/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6855 - val_loss: 0.7056\n",
      "Epoch 246/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6856 - val_loss: 0.7070\n",
      "Epoch 247/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6852 - val_loss: 0.7055\n",
      "Epoch 248/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6856 - val_loss: 0.7060\n",
      "Epoch 249/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6854 - val_loss: 0.7067\n",
      "Epoch 250/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6853 - val_loss: 0.7052\n",
      "Epoch 251/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6856 - val_loss: 0.7067\n",
      "Epoch 252/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6849 - val_loss: 0.7052\n",
      "Epoch 253/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6857 - val_loss: 0.7068\n",
      "Epoch 254/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6860 - val_loss: 0.7069\n",
      "Epoch 255/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6854 - val_loss: 0.7057\n",
      "Epoch 256/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6858 - val_loss: 0.7055\n",
      "Epoch 257/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6852 - val_loss: 0.7065\n",
      "Epoch 258/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6856 - val_loss: 0.7047\n",
      "Epoch 259/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6852 - val_loss: 0.7049\n",
      "Epoch 260/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6852 - val_loss: 0.7057\n",
      "Epoch 261/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6851 - val_loss: 0.7059\n",
      "Epoch 262/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6854 - val_loss: 0.7059\n",
      "Epoch 263/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6853 - val_loss: 0.7059\n",
      "Epoch 264/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6852 - val_loss: 0.7064\n",
      "Epoch 265/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6855 - val_loss: 0.7060\n",
      "Epoch 266/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6852 - val_loss: 0.7064\n",
      "Epoch 267/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6853 - val_loss: 0.7067\n",
      "Epoch 268/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6851 - val_loss: 0.7056\n",
      "Epoch 269/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6850 - val_loss: 0.7067\n",
      "Epoch 270/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6853 - val_loss: 0.7061\n",
      "Epoch 271/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6851 - val_loss: 0.7061\n",
      "Epoch 272/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6852 - val_loss: 0.7063\n",
      "Epoch 273/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6851 - val_loss: 0.7068\n",
      "Epoch 274/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6851 - val_loss: 0.7059\n",
      "Epoch 275/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6849 - val_loss: 0.7071\n",
      "Epoch 276/300\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6852 - val_loss: 0.7065\n"
     ]
    }
   ],
   "source": [
    "# 3 classes\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras import layers\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "import random as random\n",
    "\n",
    "# Programme principal de traitement du train set #1\n",
    "normal_trainset_1_three_class = extract_features(trainset_1, 26)\n",
    "normal_trainset_1_three_class = normalize(normal_trainset_1_three_class)\n",
    "normal_trainset_1_three_class = normal_trainset_1_three_class.sample(frac=1, random_state=42)\n",
    "\n",
    "# splitting en 3 folds\n",
    "keras.utils.set_random_seed(123)\n",
    "kf = KFold(n_splits=3, shuffle=True)\n",
    "\n",
    "y = normal_trainset_1_three_class['state'].map({'w': 2, 'r': 1, 'n': 0})\n",
    "normal_trainset_1_three_class.drop(columns=['state'], inplace=True)\n",
    "\n",
    "history_list_three_class = []\n",
    "trained_mlp_three_class = []\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(normal_trainset_1_three_class)):\n",
    "    \n",
    "    model = create_model_three_class()\n",
    "    \n",
    "    history = model.fit(x=normal_trainset_1_three_class.iloc[train_index], y=y.iloc[train_index], \n",
    "                       validation_data=(normal_trainset_1_three_class.iloc[test_index], y.iloc[test_index]),\n",
    "                       epochs=300)\n",
    "    \n",
    "    history_list_three_class.append(history)\n",
    "    trained_mlp_three_class.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "137d20c4-3016-4c68-9b58-9523b17db599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# classes\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "train_losses = np.array([history.history['loss'] for history in history_list_three_class])\n",
    "val_losses = np.array([history.history['val_loss'] for history in history_list_three_class])\n",
    "\n",
    "# Calculate mean and standard deviation for training and validation losses\n",
    "mean_train_loss = np.mean(train_losses, axis=0)\n",
    "std_train_loss = np.std(train_losses, axis=0)\n",
    "mean_val_loss = np.mean(val_losses, axis=0)\n",
    "std_val_loss = np.std(val_losses, axis=0)\n",
    "\n",
    "# Plot mean and standard deviation for training loss\n",
    "pl.plot(mean_train_loss, label='Training Loss (Mean)')\n",
    "pl.fill_between(range(len(mean_train_loss)), mean_train_loss - std_train_loss, mean_train_loss + std_train_loss, alpha=0.3, label='Training Loss (Std)')\n",
    "\n",
    "# Plot mean and standard deviation for validation loss\n",
    "pl.plot(mean_val_loss, label='Validation Loss (Mean)')\n",
    "pl.fill_between(range(len(mean_val_loss)), mean_val_loss - std_val_loss, mean_val_loss + std_val_loss, alpha=0.3, label='Validation Loss (Std)')\n",
    "\n",
    "# Add labels and legend\n",
    "pl.xlabel('Epochs')\n",
    "pl.ylabel('Loss')\n",
    "pl.legend()\n",
    "\n",
    "# Display the plot\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "7690ac28-43e9-4fcc-b52e-1db02cb4d658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step\n",
      "F1 Score - Fold 1: 0.44335850733007554\n",
      "\u001b[1m212/212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step\n",
      "F1 Score - Fold 2: 0.3174885236191322\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step\n",
      "F1 Score - Fold 3: 0.2126777251184834\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1 Score across all folds: 0.32450825202256367\n"
     ]
    }
   ],
   "source": [
    "# 3 classes\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_confusion_matrix(confusion_matrix, title):\n",
    "    # Plot confusion matrix\n",
    "    pl.figure(figsize=(8, 6))\n",
    "    sns.heatmap(confusion_matrix.astype(int), annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
    "                xticklabels=[\"n\", \"r\", \"w\"], yticklabels=[\"n\", \"r\", \"w\"])\n",
    "    pl.title(title)\n",
    "    pl.xlabel('Predicted')\n",
    "    pl.ylabel('True')\n",
    "    pl.show()\n",
    "\n",
    "f1_scores = []\n",
    "mean_confusion_matrix = np.zeros((3, 3))\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(normal_trainset_1_three_class)):\n",
    "    # Evaluate the trained model on the test fold\n",
    "    predicted_probabilities = trained_mlp_three_class[i].predict(normal_trainset_1_three_class.iloc[test_index])\n",
    "    predictions = np.argmax(predicted_probabilities, axis=1)\n",
    "    true_labels = y.iloc[test_index]\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(true_labels, predictions)\n",
    "    mean_confusion_matrix += confusion_matrix(true_labels, predictions)\n",
    "\n",
    "    # Compute confusion matrix and plot\n",
    "    #plot_confusion_matrix(cm, f'Confusion Matrix - Fold {i + 1}')\n",
    "\n",
    "    # Compute F1 score\n",
    "    f1 = f1_score(true_labels, predictions, average='micro')\n",
    "    f1_scores.append(f1)\n",
    "    print(f\"F1 Score - Fold {i + 1}: {f1}\")\n",
    "\n",
    "# Plot mean confusion matrix\n",
    "plot_confusion_matrix(mean_confusion_matrix, 'Global confusion matrix')\n",
    "\n",
    "# Calculate and display the mean F1 score across all folds\n",
    "mean_f1_score = np.mean(f1_scores)\n",
    "print(f\"Mean F1 Score across all folds: {mean_f1_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
