{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "eeb5d78c-d341-4e2b-8a51-0c4639f2efc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras import layers\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "import random as random\n",
    "\n",
    "\n",
    "trainset_1 = pd.read_csv('EEG_mouse_data_1.csv')\n",
    "trainset_2 = pd.read_csv('EEG_mouse_data_2.csv')\n",
    "testset_1 = pd.read_csv('EEG_mouse_data_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "46344ff2-a21d-4b00-83ef-e73834dbb0fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>amplitude_around_1_Hertz</th>\n",
       "      <th>amplitude_around_2_Hertz</th>\n",
       "      <th>amplitude_around_3_Hertz</th>\n",
       "      <th>amplitude_around_4_Hertz</th>\n",
       "      <th>amplitude_around_5_Hertz</th>\n",
       "      <th>amplitude_around_6_Hertz</th>\n",
       "      <th>amplitude_around_7_Hertz</th>\n",
       "      <th>amplitude_around_8_Hertz</th>\n",
       "      <th>amplitude_around_9_Hertz</th>\n",
       "      <th>...</th>\n",
       "      <th>amplitude_around_92_Hertz</th>\n",
       "      <th>amplitude_around_93_Hertz</th>\n",
       "      <th>amplitude_around_94_Hertz</th>\n",
       "      <th>amplitude_around_95_Hertz</th>\n",
       "      <th>amplitude_around_96_Hertz</th>\n",
       "      <th>amplitude_around_97_Hertz</th>\n",
       "      <th>amplitude_around_98_Hertz</th>\n",
       "      <th>amplitude_around_99_Hertz</th>\n",
       "      <th>amplitude_around_100_Hertz</th>\n",
       "      <th>amplitude_around_101_Hertz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5412</th>\n",
       "      <td>r</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>...</td>\n",
       "      <td>1.901296e-09</td>\n",
       "      <td>1.704983e-08</td>\n",
       "      <td>2.884622e-09</td>\n",
       "      <td>1.356553e-08</td>\n",
       "      <td>1.966273e-09</td>\n",
       "      <td>1.215999e-09</td>\n",
       "      <td>2.576423e-09</td>\n",
       "      <td>4.036802e-10</td>\n",
       "      <td>2.498298e-09</td>\n",
       "      <td>6.714490e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5413</th>\n",
       "      <td>r</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>...</td>\n",
       "      <td>4.003495e-08</td>\n",
       "      <td>1.000120e-08</td>\n",
       "      <td>9.468662e-09</td>\n",
       "      <td>5.499825e-09</td>\n",
       "      <td>6.204092e-09</td>\n",
       "      <td>3.570818e-09</td>\n",
       "      <td>2.537755e-09</td>\n",
       "      <td>1.054237e-09</td>\n",
       "      <td>4.613490e-09</td>\n",
       "      <td>6.546960e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5414</th>\n",
       "      <td>r</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>...</td>\n",
       "      <td>2.179355e-08</td>\n",
       "      <td>1.227923e-08</td>\n",
       "      <td>5.829200e-09</td>\n",
       "      <td>4.577287e-09</td>\n",
       "      <td>8.801728e-09</td>\n",
       "      <td>5.902430e-10</td>\n",
       "      <td>2.310058e-09</td>\n",
       "      <td>1.865220e-09</td>\n",
       "      <td>3.110150e-09</td>\n",
       "      <td>5.701210e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5415</th>\n",
       "      <td>r</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>...</td>\n",
       "      <td>2.319257e-08</td>\n",
       "      <td>9.871517e-09</td>\n",
       "      <td>4.488042e-09</td>\n",
       "      <td>3.334725e-09</td>\n",
       "      <td>3.051813e-09</td>\n",
       "      <td>4.456230e-09</td>\n",
       "      <td>8.048329e-10</td>\n",
       "      <td>1.113091e-09</td>\n",
       "      <td>6.209305e-09</td>\n",
       "      <td>7.554500e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5416</th>\n",
       "      <td>r</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>...</td>\n",
       "      <td>9.653666e-09</td>\n",
       "      <td>3.014355e-08</td>\n",
       "      <td>4.593851e-09</td>\n",
       "      <td>4.512283e-09</td>\n",
       "      <td>9.322110e-09</td>\n",
       "      <td>6.503432e-09</td>\n",
       "      <td>2.615389e-09</td>\n",
       "      <td>1.006408e-09</td>\n",
       "      <td>1.539760e-09</td>\n",
       "      <td>4.657580e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20040</th>\n",
       "      <td>r</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>...</td>\n",
       "      <td>1.555054e-08</td>\n",
       "      <td>7.315933e-09</td>\n",
       "      <td>5.992652e-09</td>\n",
       "      <td>7.769063e-09</td>\n",
       "      <td>4.875497e-09</td>\n",
       "      <td>7.579077e-09</td>\n",
       "      <td>1.414226e-09</td>\n",
       "      <td>1.162694e-09</td>\n",
       "      <td>1.753884e-09</td>\n",
       "      <td>1.989280e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20041</th>\n",
       "      <td>r</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>1.632624e-08</td>\n",
       "      <td>7.335080e-09</td>\n",
       "      <td>1.434945e-08</td>\n",
       "      <td>2.689305e-09</td>\n",
       "      <td>4.477130e-09</td>\n",
       "      <td>2.206140e-09</td>\n",
       "      <td>2.623931e-09</td>\n",
       "      <td>9.030250e-10</td>\n",
       "      <td>1.339019e-09</td>\n",
       "      <td>2.065470e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20042</th>\n",
       "      <td>r</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>...</td>\n",
       "      <td>1.658784e-08</td>\n",
       "      <td>2.275381e-08</td>\n",
       "      <td>1.671864e-08</td>\n",
       "      <td>4.833790e-09</td>\n",
       "      <td>3.721205e-09</td>\n",
       "      <td>1.598383e-09</td>\n",
       "      <td>1.304873e-09</td>\n",
       "      <td>1.373505e-09</td>\n",
       "      <td>8.776460e-10</td>\n",
       "      <td>1.517460e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20043</th>\n",
       "      <td>r</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>...</td>\n",
       "      <td>1.355185e-08</td>\n",
       "      <td>8.238853e-09</td>\n",
       "      <td>2.561817e-09</td>\n",
       "      <td>1.062316e-08</td>\n",
       "      <td>9.247750e-09</td>\n",
       "      <td>1.467894e-09</td>\n",
       "      <td>1.312522e-09</td>\n",
       "      <td>1.456176e-09</td>\n",
       "      <td>1.520392e-09</td>\n",
       "      <td>1.163740e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20044</th>\n",
       "      <td>r</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>...</td>\n",
       "      <td>1.257671e-08</td>\n",
       "      <td>4.745859e-09</td>\n",
       "      <td>3.183060e-09</td>\n",
       "      <td>9.893395e-09</td>\n",
       "      <td>1.372940e-08</td>\n",
       "      <td>2.596893e-09</td>\n",
       "      <td>2.904756e-09</td>\n",
       "      <td>2.859223e-09</td>\n",
       "      <td>3.930668e-09</td>\n",
       "      <td>4.171230e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1345 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      state  amplitude_around_1_Hertz  amplitude_around_2_Hertz  \\\n",
       "5412      r                  0.000013                  0.000005   \n",
       "5413      r                  0.000025                  0.000009   \n",
       "5414      r                  0.000006                  0.000006   \n",
       "5415      r                  0.000002                  0.000005   \n",
       "5416      r                  0.000008                  0.000014   \n",
       "...     ...                       ...                       ...   \n",
       "20040     r                  0.000007                  0.000006   \n",
       "20041     r                  0.000015                  0.000006   \n",
       "20042     r                  0.000024                  0.000007   \n",
       "20043     r                  0.000029                  0.000003   \n",
       "20044     r                  0.000013                  0.000002   \n",
       "\n",
       "       amplitude_around_3_Hertz  amplitude_around_4_Hertz  \\\n",
       "5412                   0.000005                  0.000012   \n",
       "5413                   0.000027                  0.000058   \n",
       "5414                   0.000007                  0.000016   \n",
       "5415                   0.000004                  0.000006   \n",
       "5416                   0.000007                  0.000017   \n",
       "...                         ...                       ...   \n",
       "20040                  0.000003                  0.000009   \n",
       "20041                  0.000009                  0.000003   \n",
       "20042                  0.000006                  0.000010   \n",
       "20043                  0.000004                  0.000013   \n",
       "20044                  0.000004                  0.000002   \n",
       "\n",
       "       amplitude_around_5_Hertz  amplitude_around_6_Hertz  \\\n",
       "5412                   0.000004                  0.000014   \n",
       "5413                   0.000009                  0.000013   \n",
       "5414                   0.000003                  0.000004   \n",
       "5415                   0.000006                  0.000005   \n",
       "5416                   0.000012                  0.000009   \n",
       "...                         ...                       ...   \n",
       "20040                  0.000007                  0.000001   \n",
       "20041                  0.000003                  0.000002   \n",
       "20042                  0.000004                  0.000003   \n",
       "20043                  0.000003                  0.000007   \n",
       "20044                  0.000003                  0.000003   \n",
       "\n",
       "       amplitude_around_7_Hertz  amplitude_around_8_Hertz  \\\n",
       "5412                   0.000040                  0.000009   \n",
       "5413                   0.000045                  0.000045   \n",
       "5414                   0.000021                  0.000079   \n",
       "5415                   0.000011                  0.000044   \n",
       "5416                   0.000012                  0.000004   \n",
       "...                         ...                       ...   \n",
       "20040                  0.000004                  0.000042   \n",
       "20041                  0.000002                  0.000046   \n",
       "20042                  0.000004                  0.000012   \n",
       "20043                  0.000013                  0.000008   \n",
       "20044                  0.000003                  0.000033   \n",
       "\n",
       "       amplitude_around_9_Hertz  ...  amplitude_around_92_Hertz  \\\n",
       "5412                   0.000006  ...               1.901296e-09   \n",
       "5413                   0.000025  ...               4.003495e-08   \n",
       "5414                   0.000007  ...               2.179355e-08   \n",
       "5415                   0.000005  ...               2.319257e-08   \n",
       "5416                   0.000016  ...               9.653666e-09   \n",
       "...                         ...  ...                        ...   \n",
       "20040                  0.000008  ...               1.555054e-08   \n",
       "20041                  0.000003  ...               1.632624e-08   \n",
       "20042                  0.000031  ...               1.658784e-08   \n",
       "20043                  0.000015  ...               1.355185e-08   \n",
       "20044                  0.000020  ...               1.257671e-08   \n",
       "\n",
       "       amplitude_around_93_Hertz  amplitude_around_94_Hertz  \\\n",
       "5412                1.704983e-08               2.884622e-09   \n",
       "5413                1.000120e-08               9.468662e-09   \n",
       "5414                1.227923e-08               5.829200e-09   \n",
       "5415                9.871517e-09               4.488042e-09   \n",
       "5416                3.014355e-08               4.593851e-09   \n",
       "...                          ...                        ...   \n",
       "20040               7.315933e-09               5.992652e-09   \n",
       "20041               7.335080e-09               1.434945e-08   \n",
       "20042               2.275381e-08               1.671864e-08   \n",
       "20043               8.238853e-09               2.561817e-09   \n",
       "20044               4.745859e-09               3.183060e-09   \n",
       "\n",
       "       amplitude_around_95_Hertz  amplitude_around_96_Hertz  \\\n",
       "5412                1.356553e-08               1.966273e-09   \n",
       "5413                5.499825e-09               6.204092e-09   \n",
       "5414                4.577287e-09               8.801728e-09   \n",
       "5415                3.334725e-09               3.051813e-09   \n",
       "5416                4.512283e-09               9.322110e-09   \n",
       "...                          ...                        ...   \n",
       "20040               7.769063e-09               4.875497e-09   \n",
       "20041               2.689305e-09               4.477130e-09   \n",
       "20042               4.833790e-09               3.721205e-09   \n",
       "20043               1.062316e-08               9.247750e-09   \n",
       "20044               9.893395e-09               1.372940e-08   \n",
       "\n",
       "       amplitude_around_97_Hertz  amplitude_around_98_Hertz  \\\n",
       "5412                1.215999e-09               2.576423e-09   \n",
       "5413                3.570818e-09               2.537755e-09   \n",
       "5414                5.902430e-10               2.310058e-09   \n",
       "5415                4.456230e-09               8.048329e-10   \n",
       "5416                6.503432e-09               2.615389e-09   \n",
       "...                          ...                        ...   \n",
       "20040               7.579077e-09               1.414226e-09   \n",
       "20041               2.206140e-09               2.623931e-09   \n",
       "20042               1.598383e-09               1.304873e-09   \n",
       "20043               1.467894e-09               1.312522e-09   \n",
       "20044               2.596893e-09               2.904756e-09   \n",
       "\n",
       "       amplitude_around_99_Hertz  amplitude_around_100_Hertz  \\\n",
       "5412                4.036802e-10                2.498298e-09   \n",
       "5413                1.054237e-09                4.613490e-09   \n",
       "5414                1.865220e-09                3.110150e-09   \n",
       "5415                1.113091e-09                6.209305e-09   \n",
       "5416                1.006408e-09                1.539760e-09   \n",
       "...                          ...                         ...   \n",
       "20040               1.162694e-09                1.753884e-09   \n",
       "20041               9.030250e-10                1.339019e-09   \n",
       "20042               1.373505e-09                8.776460e-10   \n",
       "20043               1.456176e-09                1.520392e-09   \n",
       "20044               2.859223e-09                3.930668e-09   \n",
       "\n",
       "       amplitude_around_101_Hertz  \n",
       "5412                 6.714490e-08  \n",
       "5413                 6.546960e-08  \n",
       "5414                 5.701210e-08  \n",
       "5415                 7.554500e-08  \n",
       "5416                 4.657580e-08  \n",
       "...                           ...  \n",
       "20040                1.989280e-08  \n",
       "20041                2.065470e-08  \n",
       "20042                1.517460e-08  \n",
       "20043                1.163740e-09  \n",
       "20044                4.171230e-08  \n",
       "\n",
       "[1345 rows x 102 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset_1[trainset_1['state'] == 'r']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "3b108bbf-90db-43f6-b853-ea5ed43fd185",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "def normalize(df):\n",
    "    headers = df.columns\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    numerical_columns = df.select_dtypes(include=['int', 'float']).columns\n",
    "    df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
    "    normalized_data = pd.DataFrame(df, columns=headers[:-1])\n",
    "\n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "4227403a-4f33-4e43-8d72-187c7153edbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainset_1 = trainset_1.iloc[:,:26]\n",
    "\n",
    "trainset_1 = normalize(trainset_1)\n",
    "X = trainset_1.drop('state', axis=1)\n",
    "y = trainset_1['state'].map({'w': 2, 'r': 1, 'n': 0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "cfa2a6be-39c8-4486-b7b6-cc0736f9a5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julien\\miniconda3\\envs\\ARN\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_63\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_63\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">352</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_66 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">35,300</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_67 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">303</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_11 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m32\u001b[0m)              │             \u001b[38;5;34m128\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_11 (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m32\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_11 (\u001b[38;5;33mFlatten\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m352\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_66 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m35,300\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_67 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │             \u001b[38;5;34m303\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">35,731</span> (139.57 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m35,731\u001b[0m (139.57 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">35,731</span> (139.57 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m35,731\u001b[0m (139.57 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras import layers\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten\n",
    "from keras.regularizers import l1, l2\n",
    "\n",
    "# momentum: [0, 0.8, 0.9, 0.99]\n",
    "# learning_rate: [0.1, 0.01, 0.001, 0.0001]\n",
    "def create_model_three_class():\n",
    "   # model = keras.Sequential()\n",
    "   # model.add(Input(shape=(X.shape[1], 1)))  # Ajouter une couche d'entrée\n",
    "   # model.add(LSTM(5))\n",
    "   # model.add(Dense(3, activation='softmax'))\n",
    "   # model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X.shape[1], 1)))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dense(3, activation='softmax'))  # Couche de sortie avec activation softmax\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_model_three_class()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269f8cf0-aa36-4a66-a874-2c8463ba079e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 1.0474 - val_accuracy: 0.8687 - val_loss: 0.4183\n",
      "Epoch 2/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8815 - loss: 0.3687 - val_accuracy: 0.8675 - val_loss: 0.4020\n",
      "Epoch 3/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8823 - loss: 0.3575 - val_accuracy: 0.8687 - val_loss: 0.3931\n",
      "Epoch 4/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8840 - loss: 0.3523 - val_accuracy: 0.8701 - val_loss: 0.3823\n",
      "Epoch 5/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8857 - loss: 0.3481 - val_accuracy: 0.8746 - val_loss: 0.3706\n",
      "Epoch 6/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8876 - loss: 0.3446 - val_accuracy: 0.8755 - val_loss: 0.3670\n",
      "Epoch 7/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8883 - loss: 0.3419 - val_accuracy: 0.8780 - val_loss: 0.3591\n",
      "Epoch 8/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8884 - loss: 0.3395 - val_accuracy: 0.8793 - val_loss: 0.3549\n",
      "Epoch 9/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8895 - loss: 0.3380 - val_accuracy: 0.8809 - val_loss: 0.3486\n",
      "Epoch 10/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8889 - loss: 0.3356 - val_accuracy: 0.8835 - val_loss: 0.3432\n",
      "Epoch 11/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8895 - loss: 0.3341 - val_accuracy: 0.8832 - val_loss: 0.3416\n",
      "Epoch 12/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8890 - loss: 0.3330 - val_accuracy: 0.8841 - val_loss: 0.3371\n",
      "Epoch 13/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8893 - loss: 0.3311 - val_accuracy: 0.8843 - val_loss: 0.3358\n",
      "Epoch 14/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8890 - loss: 0.3299 - val_accuracy: 0.8855 - val_loss: 0.3338\n",
      "Epoch 15/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8899 - loss: 0.3286 - val_accuracy: 0.8843 - val_loss: 0.3328\n",
      "Epoch 16/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8887 - loss: 0.3279 - val_accuracy: 0.8843 - val_loss: 0.3325\n",
      "Epoch 17/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8906 - loss: 0.3269 - val_accuracy: 0.8855 - val_loss: 0.3321\n",
      "Epoch 18/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8894 - loss: 0.3258 - val_accuracy: 0.8845 - val_loss: 0.3338\n",
      "Epoch 19/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8903 - loss: 0.3254 - val_accuracy: 0.8869 - val_loss: 0.3307\n",
      "Epoch 20/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8900 - loss: 0.3245 - val_accuracy: 0.8875 - val_loss: 0.3305\n",
      "Epoch 21/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8908 - loss: 0.3238 - val_accuracy: 0.8872 - val_loss: 0.3302\n",
      "Epoch 22/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8908 - loss: 0.3230 - val_accuracy: 0.8875 - val_loss: 0.3308\n",
      "Epoch 23/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8917 - loss: 0.3223 - val_accuracy: 0.8885 - val_loss: 0.3276\n",
      "Epoch 24/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8915 - loss: 0.3216 - val_accuracy: 0.8888 - val_loss: 0.3277\n",
      "Epoch 25/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8914 - loss: 0.3212 - val_accuracy: 0.8882 - val_loss: 0.3266\n",
      "Epoch 26/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8910 - loss: 0.3210 - val_accuracy: 0.8885 - val_loss: 0.3266\n",
      "Epoch 27/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8918 - loss: 0.3202 - val_accuracy: 0.8879 - val_loss: 0.3273\n",
      "Epoch 28/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8914 - loss: 0.3198 - val_accuracy: 0.8885 - val_loss: 0.3260\n",
      "Epoch 29/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8917 - loss: 0.3193 - val_accuracy: 0.8886 - val_loss: 0.3261\n",
      "Epoch 30/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8914 - loss: 0.3186 - val_accuracy: 0.8894 - val_loss: 0.3246\n",
      "Epoch 31/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8923 - loss: 0.3182 - val_accuracy: 0.8888 - val_loss: 0.3249\n",
      "Epoch 32/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8907 - loss: 0.3182 - val_accuracy: 0.8889 - val_loss: 0.3240\n",
      "Epoch 33/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8927 - loss: 0.3175 - val_accuracy: 0.8880 - val_loss: 0.3262\n",
      "Epoch 34/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8920 - loss: 0.3178 - val_accuracy: 0.8879 - val_loss: 0.3255\n",
      "Epoch 35/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8923 - loss: 0.3177 - val_accuracy: 0.8888 - val_loss: 0.3253\n",
      "Epoch 36/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8919 - loss: 0.3176 - val_accuracy: 0.8891 - val_loss: 0.3242\n",
      "Epoch 37/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8926 - loss: 0.3167 - val_accuracy: 0.8891 - val_loss: 0.3246\n",
      "Epoch 38/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8924 - loss: 0.3164 - val_accuracy: 0.8901 - val_loss: 0.3237\n",
      "Epoch 39/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8930 - loss: 0.3158 - val_accuracy: 0.8891 - val_loss: 0.3241\n",
      "Epoch 40/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8926 - loss: 0.3155 - val_accuracy: 0.8891 - val_loss: 0.3232\n",
      "Epoch 41/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8935 - loss: 0.3149 - val_accuracy: 0.8898 - val_loss: 0.3224\n",
      "Epoch 42/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8939 - loss: 0.3144 - val_accuracy: 0.8883 - val_loss: 0.3232\n",
      "Epoch 43/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8939 - loss: 0.3143 - val_accuracy: 0.8889 - val_loss: 0.3216\n",
      "Epoch 44/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8937 - loss: 0.3134 - val_accuracy: 0.8906 - val_loss: 0.3210\n",
      "Epoch 45/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8938 - loss: 0.3129 - val_accuracy: 0.8888 - val_loss: 0.3212\n",
      "Epoch 46/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8945 - loss: 0.3128 - val_accuracy: 0.8885 - val_loss: 0.3216\n",
      "Epoch 47/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8939 - loss: 0.3128 - val_accuracy: 0.8883 - val_loss: 0.3220\n",
      "Epoch 48/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8951 - loss: 0.3119 - val_accuracy: 0.8885 - val_loss: 0.3210\n",
      "Epoch 49/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8946 - loss: 0.3117 - val_accuracy: 0.8907 - val_loss: 0.3196\n",
      "Epoch 50/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8955 - loss: 0.3107 - val_accuracy: 0.8901 - val_loss: 0.3198\n",
      "Epoch 51/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8951 - loss: 0.3102 - val_accuracy: 0.8913 - val_loss: 0.3195\n",
      "Epoch 52/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8955 - loss: 0.3100 - val_accuracy: 0.8907 - val_loss: 0.3187\n",
      "Epoch 53/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8951 - loss: 0.3096 - val_accuracy: 0.8906 - val_loss: 0.3191\n",
      "Epoch 54/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8962 - loss: 0.3095 - val_accuracy: 0.8918 - val_loss: 0.3189\n",
      "Epoch 55/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8965 - loss: 0.3088 - val_accuracy: 0.8922 - val_loss: 0.3184\n",
      "Epoch 56/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8971 - loss: 0.3085 - val_accuracy: 0.8918 - val_loss: 0.3173\n",
      "Epoch 57/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8983 - loss: 0.3081 - val_accuracy: 0.8925 - val_loss: 0.3176\n",
      "Epoch 58/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8982 - loss: 0.3075 - val_accuracy: 0.8915 - val_loss: 0.3182\n",
      "Epoch 59/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8978 - loss: 0.3078 - val_accuracy: 0.8918 - val_loss: 0.3178\n",
      "Epoch 60/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8983 - loss: 0.3076 - val_accuracy: 0.8916 - val_loss: 0.3181\n",
      "Epoch 61/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8975 - loss: 0.3078 - val_accuracy: 0.8913 - val_loss: 0.3175\n",
      "Epoch 62/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8989 - loss: 0.3073 - val_accuracy: 0.8920 - val_loss: 0.3178\n",
      "Epoch 63/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8986 - loss: 0.3069 - val_accuracy: 0.8919 - val_loss: 0.3180\n",
      "Epoch 64/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8980 - loss: 0.3068 - val_accuracy: 0.8912 - val_loss: 0.3181\n",
      "Epoch 65/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8984 - loss: 0.3064 - val_accuracy: 0.8913 - val_loss: 0.3179\n",
      "Epoch 66/100\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8992 - loss: 0.3062 - val_accuracy: 0.8915 - val_loss: 0.3174\n"
     ]
    }
   ],
   "source": [
    "# 3 classes\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras import layers\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "import random as random\n",
    "from sklearn.utils import class_weight\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# splitting en 3 folds\n",
    "keras.utils.set_random_seed(123)\n",
    "kf = KFold(n_splits=3, shuffle=True)\n",
    "\n",
    "history_list_three_class = []\n",
    "trained_mlp_three_class = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    \n",
    "    model = create_model_three_class()\n",
    "    X_reshaped = X.values.reshape(X.shape[0], X.shape[1], 1)\n",
    "    y_one_hot = to_categorical(y, num_classes=3)\n",
    "\n",
    "    history = model.fit(x=X_reshaped[train_index], y=y_one_hot[train_index], \n",
    "                        validation_data=(X_reshaped[test_index], y_one_hot[test_index]),\n",
    "                        batch_size=32,\n",
    "                        epochs=100)\n",
    "    \n",
    "    history_list_three_class.append(history)\n",
    "    trained_mlp_three_class.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416adbdd-c611-40f1-bb30-22107131a75d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a719b37-9090-42a5-8390-9a553f1e96bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "train_losses = np.array([history.history['loss'] for history in history_list_three_class])\n",
    "val_losses = np.array([history.history['val_loss'] for history in history_list_three_class])\n",
    "\n",
    "# Calculate mean and standard deviation for training and validation losses\n",
    "mean_train_loss = np.mean(train_losses, axis=0)\n",
    "std_train_loss = np.std(train_losses, axis=0)\n",
    "mean_val_loss = np.mean(val_losses, axis=0)\n",
    "std_val_loss = np.std(val_losses, axis=0)\n",
    "\n",
    "# Plot mean and standard deviation for training loss\n",
    "pl.plot(mean_train_loss, label='Training Loss (Mean)')\n",
    "pl.fill_between(range(len(mean_train_loss)), mean_train_loss - std_train_loss, mean_train_loss + std_train_loss, alpha=0.3, label='Training Loss (Std)')\n",
    "\n",
    "# Plot mean and standard deviation for validation loss\n",
    "pl.plot(mean_val_loss, label='Validation Loss (Mean)')\n",
    "pl.fill_between(range(len(mean_val_loss)), mean_val_loss - std_val_loss, mean_val_loss + std_val_loss, alpha=0.3, label='Validation Loss (Std)')\n",
    "\n",
    "# Add labels and legend\n",
    "pl.xlabel('Epochs')\n",
    "pl.ylabel('Loss')\n",
    "pl.legend()\n",
    "\n",
    "# Display the plot\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df07c279-5c30-40f3-9235-904014c836b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 classes\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_confusion_matrix(confusion_matrix, title):\n",
    "    # Plot confusion matrix\n",
    "    pl.figure(figsize=(5, 5))\n",
    "    sns.heatmap(confusion_matrix.astype(int), annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
    "                xticklabels=[\"n\", \"r\", \"w\"], yticklabels=[\"n\", \"r\", \"w\"])\n",
    "    pl.title(title)\n",
    "    pl.xlabel('Predicted')\n",
    "    pl.ylabel('True')\n",
    "    pl.show()\n",
    "\n",
    "f1_scores = []\n",
    "mean_confusion_matrix = np.zeros((3, 3))\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    # Evaluate the trained model on the test fold\n",
    "    predicted_probabilities = trained_mlp_three_class[i].predict(X.iloc[test_index])\n",
    "    predictions = np.argmax(predicted_probabilities, axis=1)\n",
    "    true_labels = y.iloc[test_index]\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(true_labels, predictions)\n",
    "    mean_confusion_matrix += confusion_matrix(true_labels, predictions)\n",
    "\n",
    "    # Compute confusion matrix and plot\n",
    "    #plot_confusion_matrix(cm, f'Confusion Matrix - Fold {i + 1}')\n",
    "\n",
    "    # Compute F1 score\n",
    "    f1 = f1_score(true_labels, predictions, average='micro')\n",
    "    f1_scores.append(f1)\n",
    "    print(f\"F1 Score - Fold {i + 1}: {f1}\")\n",
    "\n",
    "# Plot mean confusion matrix\n",
    "plot_confusion_matrix(mean_confusion_matrix, 'Global confusion matrix')\n",
    "\n",
    "# Calculate and display the mean F1 score across all folds\n",
    "mean_f1_score = np.mean(f1_scores)\n",
    "print(f\"Mean F1 Score across all folds: {mean_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9248e384-71ae-4bd1-b2d4-904d66894324",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
